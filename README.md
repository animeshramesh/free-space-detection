# free-space-detection

This project is part of the **16-720 : Introduction to Computer Vision** course at Carnegie Mellon. The objective in this project is to localize the free space in an image (taken from a monocular camera) which would eventually aid in autonomous driving. 

#Todo:
- Preprocess data into patches
- Figure out how to work with patches in CNNs
- Explore simple architectures

# Dataset
[KITTI Road dataset](http://www.cvlibs.net/datasets/kitti/eval_road.php)

The road and lane estimation benchmark consists of 289 training and 290 test images. It contains three different categories of road scenes:
- uu : urban unmarked (98/100)
- um : urban marked (95/96)
- umm : urban multiple marked lanes (96/94)

Ground truth has been generated by manual annotation of the images and is available for two different road terrain types: road - the road area, i.e, the composition of all lanes, and lane - the ego-lane, i.e., the lane the vehicle is currently driving on (only available for category "um").

#Team Members:
- Animesh Ramesh
- Aditya Cherukumdi

# References
- [Free Space Detection with Deep Nets for Autonomous Driving] (http://cs231n.stanford.edu/reports/jpazhaya_final.pdf)
- [Free-Space Detection with Self-Supervised and Online Trained Fully Convolutional Networks](https://arxiv.org/pdf/1604.02316.pdf)
